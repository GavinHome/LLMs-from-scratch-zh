{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第五章：对未标记数据进行预训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章节中中使用的软件包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.2\n",
      "numpy version: 1.26.4\n",
      "transformers version: 4.46.3\n",
      "torch version: 2.5.1\n",
      "tensorflow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"transformers\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在本章中，我们实现了训练和基本模型评估代码来预训练 LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 评估生成文本模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 本节首先简要回顾如何使用上一章的代码初始化 GPT 模型\n",
    "- 然后，我们讨论 LLM 的基本评估指标\n",
    "- 最后，在本节中，我们将这些评估指标应用于训练和验证数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 使用GPT生成文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们使用上一章的代码初始化 GPT 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yxm/mambaforge/envs/LLMs/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": len(tokenizer),   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们在上面使用了 0.1 的 dropout，但现在训练 LLM 时不使用 dropout 比较常见\n",
    "- 现代 LLM 也不在 `nn.Linear` 层中对查询、键和值矩阵使用偏差向量（与早期的 GPT 模型不同），这是通过设置 `\"qkv_bias\": False` 来实现的\n",
    "- 我们将上下文长度（`context_length`）减少到仅 256 个 token，以减少训练模型的计算资源要求，而原始的 1.24 亿参数 GPT-2 模型使用了 1024 个 token\n",
    "- 这样做是为了让更多的读者能够在他们的笔记本电脑上关注和执行代码示例\n",
    "- 但是，请随意将 `context_length` 增加到 1024 个 token\n",
    "- 我们稍后还将从预训练权重中加载一个具有 1024 个 `context_length` 的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 接下来，我们使用上一章中的 `generate_text_simple` 函数来生成文本\n",
    "- 此外，我们定义了两个便利函数，`text_to_token_ids` 和 `token_ids_to_text`，用于在本章中使用的标记和文本表示之间进行转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " 每 一 次 努 力 都 让 你 感 动 了 一 眼 驴 子 。 我 看 到 ， 当 斯 特 劳 德 画 下 第 一 笔 时 ， 他 。 我 的 终 的 结\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, max_length=None, truncation=False)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist(), skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "start_context = \"每一次努力都让你感动\"\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=30,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如上所示，由于模型尚未经过训练，因此无法生成优质文本\n",
    "- 我们如何以数字形式测量或捕捉“优质文本”，以便在训练期间进行跟踪？\n",
    "- 下一小节将介绍用于计算生成输出的损失指标的指标，我们可以使用这个指标来衡量训练进度\n",
    "- 下一章关于微调 LLM 的内容还将介绍其他衡量模型质量的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 计算文本生成损失：交叉熵和困惑度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 假设我们有一个“输入”张量，其中包含 2 个训练示例（行）的标记 ID\n",
    "- 与“输入”相对应，“目标”包含我们希望模型生成的所需标记 ID\n",
    "- 请注意，“目标”是移动 1 个位置的“输入”，如第 2 章我们实现数据加载器时所述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3680, 671, 3613, 1222, 1213, 6963, 6375, 872, 2697, 1220]\n",
      "[2769, 4696, 4638, 7478, 2382, 1599, 3614, 2341, 1046, 1213]\n",
      "每 一 次 努 力 都 让 你 感\n",
      "我 真 的 非 常 喜 欢 巧 克\n",
      "一 次 努 力 都 让 你 感 动\n",
      "真 的 非 常 喜 欢 巧 克 力\n"
     ]
    }
   ],
   "source": [
    "# print(tokenizer.encode(\"每一次努力都让你感动\", add_special_tokens=False))\n",
    "# print(tokenizer.encode(\"我真的非常喜欢巧克力\", add_special_tokens=False))\n",
    "\n",
    "# print(tokenizer.decode([3680, 671,  3613, 1222, 1213, 6963, 6375, 872,  2697], add_special_tokens=False))\n",
    "# print(tokenizer.decode([2769, 4696, 4638, 7478, 2382, 1599, 3614, 2341, 1046], add_special_tokens=False))\n",
    "# print(tokenizer.decode([671,  3613, 1222, 1213, 6963, 6375, 872, 2697,  1220], add_special_tokens=False))\n",
    "# print(tokenizer.decode([4696, 4638, 7478, 2382, 1599, 3614, 2341, 1046, 1213], add_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[3680,  671,  3613, 1222, 1213, 6963, 6375, 872,  2697],   # [\"每一次努力都让你感\",\n",
    "                       [2769,  4696, 4638, 7478, 2382, 1599, 3614, 2341, 1046]])   #  \"我真的非常喜欢巧克\"]\n",
    "\n",
    "targets = torch.tensor([[671,  3613, 1222, 1213, 6963, 6375, 872, 2697,  1220],  # [\"一次努力都让你感动\",\n",
    "                        [4696, 4638, 7478, 2382, 1599, 3614, 2341, 1046, 1213]]) #  \"真的非常喜欢巧克力\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将“输入”输入到模型中，我们获得 2 个输入示例的 logits 向量，每个示例由 9 个标记组成\n",
    "- 每个标记都是一个 21,128 维向量，与词汇表的大小相对应\n",
    "- 应用 softmax 函数，我们可以将 logits 张量转换为包含概率分数的相同维度的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 21128])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如上一章所述，我们可以应用 `argmax` 函数将概率分数转换为预测的 token ID\n",
    "- 上面的 softmax 函数为每个 token 生成一个 21,128 维向量；`argmax` 函数返回此向量中最高概率分数的位置，即给定 token 的预测 token ID\n",
    "- 由于我们有 2 个输入批次，每个批次有 3 个标记，因此我们获得 2 乘 3 的预测标记 ID："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[20213],\n",
      "         [ 1357],\n",
      "         [14017],\n",
      "         [10361],\n",
      "         [  652],\n",
      "         [13444],\n",
      "         [10938],\n",
      "         [17176],\n",
      "         [ 7797]],\n",
      "\n",
      "        [[18073],\n",
      "         [ 8195],\n",
      "         [ 5818],\n",
      "         [  986],\n",
      "         [10773],\n",
      "         [20497],\n",
      "         [  234],\n",
      "         [19857],\n",
      "         [15688]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果我们解码这些标记，我们会发现它们与我们希望模型预测的标记（即目标标记）有很大不同："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1: 一 次 努 力 都 让 你 感 动\n",
      "Outputs batch 1: ##钒 取倪ae ㄌน 285灏 魚\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这是因为模型尚未经过训练\n",
    "- 为了训练模型，我们需要知道它距离正确的预测（目标）有多远"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目标索引对应的token概率如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一个文本: tensor([4.1327e-05, 8.7313e-05, 3.3802e-05, 2.7975e-05, 3.3695e-05, 3.4557e-05,\n",
      "        1.5627e-05, 3.4214e-05, 3.7327e-05])\n",
      "第二个文本: tensor([8.4292e-05, 1.9261e-05, 1.3799e-05, 1.1468e-04, 2.1015e-05, 4.4112e-05,\n",
      "        5.4746e-05, 4.3250e-05, 3.5221e-05])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2, 3, 4, 5, 6, 7, 8], targets[text_idx]]\n",
    "print(\"第一个文本:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2, 3, 4, 5, 6, 7, 8], targets[text_idx]]\n",
    "print(\"第二个文本:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们希望最大化所有这些值，使它们的概率接近 1\n",
    "- 在数学优化中，最大化概率分数的对数比最大化概率分数本身更容易；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.0940,  -9.3460, -10.2950, -10.4842, -10.2982, -10.2729, -11.0665,\n",
      "        -10.2829, -10.1958,  -9.3812, -10.8575, -11.1909,  -9.0733, -10.7703,\n",
      "        -10.0288,  -9.8128, -10.0485, -10.2539])\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 接下来，我们计算平均对数概率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.2085)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目标是通过优化模型权重使这个平均对数概率尽可能大\n",
    "- 由于对数，最大可能值为 0，而我们目前距离 0 还很远"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在深度学习中，标准惯例是最小化*负*平均对数概率值，而不是最大化平均对数概率值；在我们的例子中，在深度学习中，我们不会最大化 -10.7722 以使其接近 0，而是会最小化 10.7722 以使其接近 0\n",
    "- -10.7722 的负值，即 10.7722，在深度学习中也称为交叉熵损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.2085)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PyTorch 已经实现了一个 `cross_entropy` 函数来执行前面的步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在应用“cross_entropy”函数之前，让我们检查一下 logits 和目标的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 9, 21128])\n",
      "Targets shape: torch.Size([2, 9])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对于 PyTorch 中的 `cross_entropy` 函数，我们希望通过在批量维度上组合这些张量来展平它们："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([18, 21128])\n",
      "Flattened targets: torch.Size([18])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 请注意，目标是标记 ID，它们也代表我们想要最大化的 logits 张量中的索引位置\n",
    "- PyTorch 中的 `cross_entropy` 函数将自动负责在要最大化的 logits 中的标记索引上内部应用 softmax 和对数概率计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.2085)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 与交叉熵损失相关的一个概念是 LLM 的困惑度\n",
    "- 困惑度只是交叉熵损失的指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(27132.2910)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 困惑度通常被认为更具可解释性，因为它可以理解为模型在每个步骤中不确定的有效词汇量（在上面的例子中，即 27,132 个字或标记）\n",
    "- 换句话说，困惑度衡量了模型预测的概率分布与数据集中单词的实际分布的匹配程度\n",
    "- 与损失类似，困惑度越低，表示模型预测越接近实际分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 计算训练集和验证集损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们使用相对较小的数据集来训练 LLM（实际上，只有一个短篇故事）\n",
    "- 原因是：\n",
    "  - 您可以在没有合适 GPU 的笔记本电脑上几分钟内运行代码示例\n",
    "  - 训练完成相对较快（几分钟而不是几周），这对于教育目的很有帮助\n",
    "  - 我们使用来自公共领域的文本，可以将其包含在此 GitHub 存储库中，而不会侵犯任何使用权或增加存储库大小\n",
    "\n",
    "- 例如，Llama 2 7B 需要在 A100 GPU 上花费 184,320 个 GPU 小时才能在 2 万亿个令牌上进行训练\n",
    "  - 在撰写本文时，AWS 上 8xA100 云服务器的每小时成本约为 \\$30\n",
    "  - 因此，通过开箱即用的计算，训练这个 LLM 将花费 184,320 / 8 * \\$30 = \\$690,000\n",
    "\n",
    "- 下面，我们使用与第 2 章相同的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/GavinHome/LLMs-from-scratch-zh/main/ch02/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过打印前 100 个字和后 100 个字来快速检查文本是否加载正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我一直认为杰克·吉斯伯恩是一个廉价的天才——尽管他是个不错的家伙——所以当我听说他在事业巅峰时放弃了绘画，娶了一位富有的寡妇，并在里维埃拉的一座别墅里安顿下来时，我并不感到特别惊讶。（虽然我更倾向于\n"
     ]
    }
   ],
   "source": [
    "# First 100 characters\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——只是在德文郡从一次心脏病发作恢复期间，用颤抖的手记录下的一个笔记。只是一个笔记！但它讲述了他的整个历史。每一笔都充满了多年的耐心而蔑视的坚持。随波逐流的人永远学不会那种强大的逆流而上的笔触……”\n"
     ]
    }
   ],
   "source": [
    "# Last 100 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 2806\n",
      "Tokens: 2758\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 文本只有 2,758 个 token，对于训练 LLM 来说太短了，但同样，这是出于学习目的（我们稍后还将加载预训练的权重）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 接下来，我们将数据集分为训练集和验证集，并使用第 2 章中的数据加载器为 LLM 训练准备批次\n",
    "- 出于可视化目的，下图假设 `max_length=6`，但对于训练加载器，我们将 `max_length` 设置为 LLM 支持的上下文长度\n",
    "- 下图仅显示输入标记以方便理解\n",
    "  - 由于我们训练 LLM 来预测文本中的下一个单词，因此目标看起来与这些输入相同，只是目标移动了一个位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.80\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们使用相对较小的批处理大小来减少计算资源需求，因为数据集一​​开始就很小\n",
    "- 例如，Llama 2 7B 的批处理大小为 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可选检查数据是否已正确加载："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 另一个可选检查是检查令牌大小是否在预期的范围内："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 2048\n",
      "Validation tokens: 512\n",
      "All tokens: 2560\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 接下来，我们实现一个效用函数来计算给定批次的交叉熵损失\n",
    "- 此外，我们实现第二个效用函数来计算数据加载器中用户指定批次数量的损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果您的机器配有支持 CUDA 的 GPU，LLM 将在 GPU 上进行训练，而无需对代码进行任何更改\n",
    "- 通过 `device` 设置，我们确保数据加载到与 LLM 模型相同的设备上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.11281442642212\n",
      "Validation loss: 10.10297679901123\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(42) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 训练一个LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在本节中，我们最终实现了训练 LLM 的代码\n",
    "- 我们专注于一个简单的训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 现在，让我们使用上面定义的训练函数来训练 LLM："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 8.727, Val loss 9.104\n",
      "每 一 次 努 力 都 让 你 感 动 我\n",
      "Ep 2 (Step 000005): Train loss 6.972, Val loss 6.983\n",
      "每 一 次 努 力 都 让 你 感 动 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的 的\n",
      "Ep 3 (Step 000010): Train loss 5.668, Val loss 5.832\n",
      "每 一 次 努 力 都 让 你 感 动 我 ， 我 ， 我 。\n",
      "Ep 4 (Step 000015): Train loss 4.514, Val loss 5.163\n",
      "每 一 次 努 力 都 让 你 感 动 ， 我 不 是 我 不 我 不 到 ， 我 不 到 ， 我 不 到 ， 我 不 到 ， 我 不 到 了 我 不 到 ， 我 不 是 我 不 到 ， 我 不 到 他 是 一 个 到 他 是 我 不 到\n",
      "每 一 次 努 力 都 让 你 感 动 是 一 个 次 ， 我 不 是 一 个 我 的 作 品 他 的 一 个\n",
      "Ep 6 (Step 000020): Train loss 3.413, Val loss 4.921\n",
      "每 一 次 努 力 都 让 你 感 动 我 的 一 次 ， 他 的 我 我 的 我 不 到 这 样 的 他 是 我 的 我 的 我 的 我 的 我 ， 这 个 我 的 我 的\n",
      "Ep 7 (Step 000025): Train loss 2.500, Val loss 4.222\n",
      "每 一 次 努 力 都 让 你 感 动 了 一 次 ， 当 然 的\n",
      "Ep 8 (Step 000030): Train loss 1.755, Val loss 3.816\n",
      "每 一 次 努 力 都 让 你 感 动 了 我 一 个 廉 价 我 发 作 品 并 不 能 看 到 他 的 部 分 。 我 的 那 些 华 丽 的 部 分 。\n",
      "Ep 9 (Step 000035): Train loss 1.128, Val loss 3.648\n",
      "每 一 次 努 力 都 让 你 感 动 了 一 个 不 能 平 我 看 到 ， 当 斯 特 劳 德 画 下 第 一 个 时 ， 他 。 我 的 手 的 结 果 会 是 什 么 。 他 已 经 掌 握 了 一 个 主 题 ， 他 的 着\n",
      "每 一 次 努 力 都 让 你 感 动 在 五 分 钟 内 告 诉 你 他 是 个 不 需 要 很 长 时 间 我 的 满 足 而 感 到 高 兴 ： 很 高 兴 能 有 这 样 一 个 主 题 ， 他 的 着\n",
      "Training completed in 1.45 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"每一次努力都让你感动\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 查看上面的结果，我们可以看到模型一开始会生成难以理解的字符串，而到最后，它能够生成语法或多或少正确的句子\n",
    "- 但是，基于训练和验证集损失，我们可以看到模型开始过度拟合\n",
    "- 如果我们检查它在最后写的几段话，我们会发现它们逐字逐句地包含在训练集中——它只是记住了训练数据\n",
    "- 稍后，我们将介绍可以在一定程度上减轻这种记忆的解码策略\n",
    "- 请注意，这里发生过度拟合是因为我们有一个非常非常小的训练集，并且我们对其进行了多次迭代\n",
    "  - 这里的 LLM 培训主要用于教育目的；我们主要想看看模型可以学会生成连贯的文本\n",
    "  - 我们不是花费数周或数月在大量昂贵的硬件上训练这个模型，而是稍后加载预训练的权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 控制随机性的解码策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用相对较小的 LLM 作为我们上面训练的 GPT 模型，推理相对便宜，因此如果您在上面使用 GPU 进行训练，则无需使用 GPU\n",
    "- 使用我们之前在简单训练函数中使用的 `generate_text_simple` 函数（来自上一章），我们可以一次生成一个新文本\n",
    "- 如第 5.1.2 节所述，下一个生成的标记是词汇表中所有标记中概率得分最大的标记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " 每 一 次 努 力 都 让 你 感 动 在 五 分 钟 内 告 诉 你 他 是 个 不 需 要 很 长 时 间 我 的 满 足 而 感 到 高 兴 ： 很 高 兴 能 有 这 样 一 个 主 题 ， 他 的 着\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "# tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"每一次努力都让你感动\", tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 即使我们多次执行上面的 `generate_text_simple` 函数，LLM 也始终会生成相同的输出\n",
    "- 我们现在引入两个概念，即所谓的解码策略，来修改 `generate_text_simple`：*温度缩放* 和 *top-k* 采样\n",
    "- 这些将允许模型控制生成文本的随机性和多样性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 温度缩放"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 以前，我们总是使用 `torch.argmax` 将概率最高的标记作为下一个标记进行采样\n",
    "- 为了增加多样性，我们可以使用 `torch.multinomial(probs, num_samples=1)` 从概率分布中采样下一个标记\n",
    "- 在这里，每个索引被选中的概率对应于其在输入张量中的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们可以通过称为温度缩放的概念来控制分布和选择过程\n",
    "- “温度缩放”只是一个花哨的词，用于将 logits 除以大于 0 的数字\n",
    "- 在应用 softmax 后，大于 1 的温度将产生更均匀分布的标记概率\n",
    "- 在应用 softmax 后，小于 1 的温度将产生更可信（更尖锐或更尖锐）的分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k 抽样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 为了能够使用更高的温度来增加输出多样性并降低无意义句子的概率，我们可以将采样的标记限制为前 k 个最可能的标记："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 修改文本生成函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 前两小节介绍了温度采样和 top-k 采样\n",
    "- 让我们使用这两个概念修改我们之前通过 LLM 生成文本时使用的 `generate_simple` 函数，创建一个新的 `generate` 函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " 每 一 次 努 力 都 让 你 ， 他 在 看 但 这 会 那 生 了 他 而 且 有 人 。 画 下 第 一 他 已 经 有 二 十 上 的 作 品 ； 果 会 ， 这 里 时 候 逐 要 么 时 ， 娶 他 ； 他 只 是\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"每一次努力都让你\", tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 在 PyTorch 中加载和保存模型权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 训练 LLM 的计算成本很高，因此保存和加载 LLM 权重的能力至关重要\n",
    "- PyTorch 中推荐的方式是通过将 `torch.save` 函数应用于 `.state_dict()` 方法来保存模型权重，即所谓的 `state_dict`："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通常使用 Adam 或 AdamW 等自适应优化器来训练 LLM，而不是使用常规的 SGD\n",
    "- 这些自适应优化器会为每个模型权重存储额外的参数，因此如果我们计划稍后继续进行预训练，那么保存这些参数也是有意义的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 然后我们可以将模型权重加载到新的 `GPTModel` 模型实例中，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 117,677,568\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 从 OpenAI 加载预训练权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 之前，我们仅使用一本非常小的短篇小说训练了一个小型 GPT-2 模型，用于教育目的\n",
    "- 幸运的是，我们不必花费数万到数十万美元在大型预训练语料库上对模型进行预训练，但可以加载 OpenAI 提供的预训练权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 首先，一些样板代码用于从 OpenAI 下载文件并将权重加载到 Python 中\n",
    "- 由于 OpenAI 使用了 [TensorFlow](https://www.tensorflow.org/)，因此我们必须安装并使用 TensorFlow 来加载权重；[tqdm](https://github.com/tqdm/tqdm) 是一个进度条库\n",
    "- 取消注释并运行下一个单元以安装所需的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "tqdm version: 4.67.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 13:44:10.242115: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-29 13:44:10.253041: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732859050.266161   26104 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732859050.270144   26104 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-29 13:44:10.284978: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Relative import from the gpt_download.py contained in this folder\n",
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 然后我们可以下载 1.24 亿个参数模型的模型权重，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 另外，“355M”、“774M”和“1558M”也是支持的“model_size”参数\n",
    "- 下图总结了这些不同大小的模型之间的区别："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-sizes.webp?timestamp=123\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上面，我们将 124M GPT-2 模型权重加载到 Python 中，但我们仍然需要将它们传输到我们的 `GPTModel` 实例中\n",
    "- 首先，我们初始化一个新的 GPTModel 实例\n",
    "- 请注意，原始 GPT 模型使用偏差向量初始化了多头注意模块中查询、键和值矩阵的线性层，这不是必需的或推荐的；但是，为了能够正确加载权重，我们也必须通过在我们的实现中将 `qkv_bias` 设置为 `True` 来启用这些权重\n",
    "- 我们还使用了原始 GPT-2 模型使用的 `1024` 令牌上下文长度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 请注意：之前是针对中文的token化，要使用gpt2预训练权重，我们需要将一些参数改回适合gpt2的值，例如vocab_size，以及将编码和解码方法使用tiktoken来实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "import tiktoken\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 下一个任务是将 OpenAI 权重分配给我们的 `GPTModel` 实例中的相应权重张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果模型加载正确，我们可以使用它使用我们之前的“generate”函数来生成新文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward the goal, but you also move forward.\n",
      "\n",
      "\"I think there's a lot of people who think that the\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们知道我们正确地加载了模型权重，因为模型可以生成连贯的文本；如果我们犯了一个小错误，模型就无法做到这一点"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
