{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬äº”ç« ï¼šå¯¹æœªæ ‡è®°æ•°æ®è¿›è¡Œé¢„è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ¬ç« èŠ‚ä¸­ä¸­ä½¿ç”¨çš„è½¯ä»¶åŒ…ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.2\n",
      "numpy version: 1.26.4\n",
      "transformers version: 4.46.3\n",
      "torch version: 2.5.1\n",
      "tensorflow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"transformers\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å®ç°äº†è®­ç»ƒå’ŒåŸºæœ¬æ¨¡å‹è¯„ä¼°ä»£ç æ¥é¢„è®­ç»ƒ LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 è¯„ä¼°ç”Ÿæˆæ–‡æœ¬æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æœ¬èŠ‚é¦–å…ˆç®€è¦å›é¡¾å¦‚ä½•ä½¿ç”¨ä¸Šä¸€ç« çš„ä»£ç åˆå§‹åŒ– GPT æ¨¡å‹\n",
    "- ç„¶åï¼Œæˆ‘ä»¬è®¨è®º LLM çš„åŸºæœ¬è¯„ä¼°æŒ‡æ ‡\n",
    "- æœ€åï¼Œåœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è¿™äº›è¯„ä¼°æŒ‡æ ‡åº”ç”¨äºè®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 ä½¿ç”¨GPTç”Ÿæˆæ–‡æœ¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æˆ‘ä»¬ä½¿ç”¨ä¸Šä¸€ç« çš„ä»£ç åˆå§‹åŒ– GPT æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": len(tokenizer),   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æˆ‘ä»¬åœ¨ä¸Šé¢ä½¿ç”¨äº† 0.1 çš„ dropoutï¼Œä½†ç°åœ¨è®­ç»ƒ LLM æ—¶ä¸ä½¿ç”¨ dropout æ¯”è¾ƒå¸¸è§\n",
    "- ç°ä»£ LLM ä¹Ÿä¸åœ¨ `nn.Linear` å±‚ä¸­å¯¹æŸ¥è¯¢ã€é”®å’Œå€¼çŸ©é˜µä½¿ç”¨åå·®å‘é‡ï¼ˆä¸æ—©æœŸçš„ GPT æ¨¡å‹ä¸åŒï¼‰ï¼Œè¿™æ˜¯é€šè¿‡è®¾ç½® `\"qkv_bias\": False` æ¥å®ç°çš„\n",
    "- æˆ‘ä»¬å°†ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆ`context_length`ï¼‰å‡å°‘åˆ°ä»… 256 ä¸ª tokenï¼Œä»¥å‡å°‘è®­ç»ƒæ¨¡å‹çš„è®¡ç®—èµ„æºè¦æ±‚ï¼Œè€ŒåŸå§‹çš„ 1.24 äº¿å‚æ•° GPT-2 æ¨¡å‹ä½¿ç”¨äº† 1024 ä¸ª token\n",
    "- è¿™æ ·åšæ˜¯ä¸ºäº†è®©æ›´å¤šçš„è¯»è€…èƒ½å¤Ÿåœ¨ä»–ä»¬çš„ç¬”è®°æœ¬ç”µè„‘ä¸Šå…³æ³¨å’Œæ‰§è¡Œä»£ç ç¤ºä¾‹\n",
    "- ä½†æ˜¯ï¼Œè¯·éšæ„å°† `context_length` å¢åŠ åˆ° 1024 ä¸ª token\n",
    "- æˆ‘ä»¬ç¨åè¿˜å°†ä»é¢„è®­ç»ƒæƒé‡ä¸­åŠ è½½ä¸€ä¸ªå…·æœ‰ 1024 ä¸ª `context_length` çš„æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸Šä¸€ç« ä¸­çš„ `generate_text_simple` å‡½æ•°æ¥ç”Ÿæˆæ–‡æœ¬\n",
    "- æ­¤å¤–ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸¤ä¸ªä¾¿åˆ©å‡½æ•°ï¼Œ`text_to_token_ids` å’Œ `token_ids_to_text`ï¼Œç”¨äºåœ¨æœ¬ç« ä¸­ä½¿ç”¨çš„æ ‡è®°å’Œæ–‡æœ¬è¡¨ç¤ºä¹‹é—´è¿›è¡Œè½¬æ¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " æ¯ ä¸€ æ¬¡ åŠª åŠ› éƒ½ è®© ä½  æ„Ÿ åŠ¨ æ… é–ç¬ ç†¬rn à¸¢ ğŸ˜‚ é¼¾ èŒ¹å­¸â“’ çº¨ åŠ‘ 1b å¸…èº« x7 Î¸é³… amg ç¿»200sday æµ´ã„ã¦ ios10 nokia 1918 æ„› pixnetfacebookyahoo\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, max_length=None, truncation=False)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist(), skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "start_context = \"æ¯ä¸€æ¬¡åŠªåŠ›éƒ½è®©ä½ æ„ŸåŠ¨\"\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=30,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å¦‚ä¸Šæ‰€ç¤ºï¼Œç”±äºæ¨¡å‹å°šæœªç»è¿‡è®­ç»ƒï¼Œå› æ­¤æ— æ³•ç”Ÿæˆä¼˜è´¨æ–‡æœ¬\n",
    "- æˆ‘ä»¬å¦‚ä½•ä»¥æ•°å­—å½¢å¼æµ‹é‡æˆ–æ•æ‰â€œä¼˜è´¨æ–‡æœ¬â€ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒæœŸé—´è¿›è¡Œè·Ÿè¸ªï¼Ÿ\n",
    "- ä¸‹ä¸€å°èŠ‚å°†ä»‹ç»ç”¨äºè®¡ç®—ç”Ÿæˆè¾“å‡ºçš„æŸå¤±æŒ‡æ ‡çš„æŒ‡æ ‡ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªæŒ‡æ ‡æ¥è¡¡é‡è®­ç»ƒè¿›åº¦\n",
    "- ä¸‹ä¸€ç« å…³äºå¾®è°ƒ LLM çš„å†…å®¹è¿˜å°†ä»‹ç»å…¶ä»–è¡¡é‡æ¨¡å‹è´¨é‡çš„æ–¹æ³•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 è®¡ç®—æ–‡æœ¬ç”ŸæˆæŸå¤±ï¼šäº¤å‰ç†µå’Œå›°æƒ‘åº¦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªâ€œè¾“å…¥â€å¼ é‡ï¼Œå…¶ä¸­åŒ…å« 2 ä¸ªè®­ç»ƒç¤ºä¾‹ï¼ˆè¡Œï¼‰çš„æ ‡è®° ID\n",
    "- ä¸â€œè¾“å…¥â€ç›¸å¯¹åº”ï¼Œâ€œç›®æ ‡â€åŒ…å«æˆ‘ä»¬å¸Œæœ›æ¨¡å‹ç”Ÿæˆçš„æ‰€éœ€æ ‡è®° ID\n",
    "- è¯·æ³¨æ„ï¼Œâ€œç›®æ ‡â€æ˜¯ç§»åŠ¨ 1 ä¸ªä½ç½®çš„â€œè¾“å…¥â€ï¼Œå¦‚ç¬¬ 2 ç« æˆ‘ä»¬å®ç°æ•°æ®åŠ è½½å™¨æ—¶æ‰€è¿°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3680, 671, 3613, 1222, 1213, 6963, 6375, 872, 2697, 1220]\n",
      "[2769, 4696, 4638, 7478, 2382, 1599, 3614, 2341, 1046, 1213]\n",
      "æ¯ ä¸€ æ¬¡ åŠª åŠ› éƒ½ è®© ä½  æ„Ÿ\n",
      "æˆ‘ çœŸ çš„ é å¸¸ å–œ æ¬¢ å·§ å…‹\n",
      "ä¸€ æ¬¡ åŠª åŠ› éƒ½ è®© ä½  æ„Ÿ åŠ¨\n",
      "çœŸ çš„ é å¸¸ å–œ æ¬¢ å·§ å…‹ åŠ›\n"
     ]
    }
   ],
   "source": [
    "# print(tokenizer.encode(\"æ¯ä¸€æ¬¡åŠªåŠ›éƒ½è®©ä½ æ„ŸåŠ¨\", add_special_tokens=False))\n",
    "# print(tokenizer.encode(\"æˆ‘çœŸçš„éå¸¸å–œæ¬¢å·§å…‹åŠ›\", add_special_tokens=False))\n",
    "\n",
    "# print(tokenizer.decode([3680, 671,  3613, 1222, 1213, 6963, 6375, 872,  2697], add_special_tokens=False))\n",
    "# print(tokenizer.decode([2769, 4696, 4638, 7478, 2382, 1599, 3614, 2341, 1046], add_special_tokens=False))\n",
    "# print(tokenizer.decode([671,  3613, 1222, 1213, 6963, 6375, 872, 2697,  1220], add_special_tokens=False))\n",
    "# print(tokenizer.decode([4696, 4638, 7478, 2382, 1599, 3614, 2341, 1046, 1213], add_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[3680,  671,  3613, 1222, 1213, 6963, 6375, 872,  2697],   # [\"æ¯ä¸€æ¬¡åŠªåŠ›éƒ½è®©ä½ æ„Ÿ\",\n",
    "                       [2769,  4696, 4638, 7478, 2382, 1599, 3614, 2341, 1046]])   #  \"æˆ‘çœŸçš„éå¸¸å–œæ¬¢å·§å…‹\"]\n",
    "\n",
    "targets = torch.tensor([[671,  3613, 1222, 1213, 6963, 6375, 872, 2697,  1220],  # [\"ä¸€æ¬¡åŠªåŠ›éƒ½è®©ä½ æ„ŸåŠ¨\",\n",
    "                        [4696, 4638, 7478, 2382, 1599, 3614, 2341, 1046, 1213]]) #  \"çœŸçš„éå¸¸å–œæ¬¢å·§å…‹åŠ›\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å°†â€œè¾“å…¥â€è¾“å…¥åˆ°æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬è·å¾— 2 ä¸ªè¾“å…¥ç¤ºä¾‹çš„ logits å‘é‡ï¼Œæ¯ä¸ªç¤ºä¾‹ç”± 9 ä¸ªæ ‡è®°ç»„æˆ\n",
    "- æ¯ä¸ªæ ‡è®°éƒ½æ˜¯ä¸€ä¸ª 21,128 ç»´å‘é‡ï¼Œä¸è¯æ±‡è¡¨çš„å¤§å°ç›¸å¯¹åº”\n",
    "- åº”ç”¨ softmax å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥å°† logits å¼ é‡è½¬æ¢ä¸ºåŒ…å«æ¦‚ç‡åˆ†æ•°çš„ç›¸åŒç»´åº¦çš„å¼ é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 9, 21128])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å¦‚ä¸Šä¸€ç« æ‰€è¿°ï¼Œæˆ‘ä»¬å¯ä»¥åº”ç”¨ `argmax` å‡½æ•°å°†æ¦‚ç‡åˆ†æ•°è½¬æ¢ä¸ºé¢„æµ‹çš„ token ID\n",
    "- ä¸Šé¢çš„ softmax å‡½æ•°ä¸ºæ¯ä¸ª token ç”Ÿæˆä¸€ä¸ª 21,128 ç»´å‘é‡ï¼›`argmax` å‡½æ•°è¿”å›æ­¤å‘é‡ä¸­æœ€é«˜æ¦‚ç‡åˆ†æ•°çš„ä½ç½®ï¼Œå³ç»™å®š token çš„é¢„æµ‹ token ID\n",
    "- ç”±äºæˆ‘ä»¬æœ‰ 2 ä¸ªè¾“å…¥æ‰¹æ¬¡ï¼Œæ¯ä¸ªæ‰¹æ¬¡æœ‰ 3 ä¸ªæ ‡è®°ï¼Œå› æ­¤æˆ‘ä»¬è·å¾— 2 ä¹˜ 3 çš„é¢„æµ‹æ ‡è®° IDï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[20213],\n",
      "         [ 1357],\n",
      "         [14017],\n",
      "         [10361],\n",
      "         [  652],\n",
      "         [13444],\n",
      "         [10938],\n",
      "         [17176],\n",
      "         [ 7797]],\n",
      "\n",
      "        [[18073],\n",
      "         [ 8195],\n",
      "         [ 5818],\n",
      "         [  986],\n",
      "         [10773],\n",
      "         [20497],\n",
      "         [  234],\n",
      "         [19857],\n",
      "         [15688]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å¦‚æœæˆ‘ä»¬è§£ç è¿™äº›æ ‡è®°ï¼Œæˆ‘ä»¬ä¼šå‘ç°å®ƒä»¬ä¸æˆ‘ä»¬å¸Œæœ›æ¨¡å‹é¢„æµ‹çš„æ ‡è®°ï¼ˆå³ç›®æ ‡æ ‡è®°ï¼‰æœ‰å¾ˆå¤§ä¸åŒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1: ä¸€ æ¬¡ åŠª åŠ› éƒ½ è®© ä½  æ„Ÿ åŠ¨\n",
      "Outputs batch 1: ##é’’ å–å€ªae ã„Œà¸™ 285ç é­š\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- è¿™æ˜¯å› ä¸ºæ¨¡å‹å°šæœªç»è¿‡è®­ç»ƒ\n",
    "- ä¸ºäº†è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“å®ƒè·ç¦»æ­£ç¡®çš„é¢„æµ‹ï¼ˆç›®æ ‡ï¼‰æœ‰å¤šè¿œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ç›®æ ‡ç´¢å¼•å¯¹åº”çš„tokenæ¦‚ç‡å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¬¬ä¸€ä¸ªæ–‡æœ¬: tensor([4.1327e-05, 8.7313e-05, 3.3802e-05, 2.7975e-05, 3.3695e-05, 3.4557e-05,\n",
      "        1.5627e-05, 3.4214e-05, 3.7327e-05])\n",
      "ç¬¬äºŒä¸ªæ–‡æœ¬: tensor([8.4292e-05, 1.9261e-05, 1.3799e-05, 1.1468e-04, 2.1015e-05, 4.4112e-05,\n",
      "        5.4746e-05, 4.3250e-05, 3.5221e-05])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2, 3, 4, 5, 6, 7, 8], targets[text_idx]]\n",
    "print(\"ç¬¬ä¸€ä¸ªæ–‡æœ¬:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2, 3, 4, 5, 6, 7, 8], targets[text_idx]]\n",
    "print(\"ç¬¬äºŒä¸ªæ–‡æœ¬:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æˆ‘ä»¬å¸Œæœ›æœ€å¤§åŒ–æ‰€æœ‰è¿™äº›å€¼ï¼Œä½¿å®ƒä»¬çš„æ¦‚ç‡æ¥è¿‘ 1\n",
    "- åœ¨æ•°å­¦ä¼˜åŒ–ä¸­ï¼Œæœ€å¤§åŒ–æ¦‚ç‡åˆ†æ•°çš„å¯¹æ•°æ¯”æœ€å¤§åŒ–æ¦‚ç‡åˆ†æ•°æœ¬èº«æ›´å®¹æ˜“ï¼›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.0940,  -9.3460, -10.2950, -10.4842, -10.2982, -10.2729, -11.0665,\n",
      "        -10.2829, -10.1958,  -9.3812, -10.8575, -11.1909,  -9.0733, -10.7703,\n",
      "        -10.0288,  -9.8128, -10.0485, -10.2539])\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è®¡ç®—å¹³å‡å¯¹æ•°æ¦‚ç‡ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.2085)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ç›®æ ‡æ˜¯é€šè¿‡ä¼˜åŒ–æ¨¡å‹æƒé‡ä½¿è¿™ä¸ªå¹³å‡å¯¹æ•°æ¦‚ç‡å°½å¯èƒ½å¤§\n",
    "- ç”±äºå¯¹æ•°ï¼Œæœ€å¤§å¯èƒ½å€¼ä¸º 0ï¼Œè€Œæˆ‘ä»¬ç›®å‰è·ç¦» 0 è¿˜å¾ˆè¿œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæ ‡å‡†æƒ¯ä¾‹æ˜¯æœ€å°åŒ–*è´Ÿ*å¹³å‡å¯¹æ•°æ¦‚ç‡å€¼ï¼Œè€Œä¸æ˜¯æœ€å¤§åŒ–å¹³å‡å¯¹æ•°æ¦‚ç‡å€¼ï¼›åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œåœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬ä¸ä¼šæœ€å¤§åŒ– -10.7722 ä»¥ä½¿å…¶æ¥è¿‘ 0ï¼Œè€Œæ˜¯ä¼šæœ€å°åŒ– 10.7722 ä»¥ä½¿å…¶æ¥è¿‘ 0\n",
    "- -10.7722 çš„è´Ÿå€¼ï¼Œå³ 10.7722ï¼Œåœ¨æ·±åº¦å­¦ä¹ ä¸­ä¹Ÿç§°ä¸ºäº¤å‰ç†µæŸå¤±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.2085)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PyTorch å·²ç»å®ç°äº†ä¸€ä¸ª `cross_entropy` å‡½æ•°æ¥æ‰§è¡Œå‰é¢çš„æ­¥éª¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- åœ¨åº”ç”¨â€œcross_entropyâ€å‡½æ•°ä¹‹å‰ï¼Œè®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹ logits å’Œç›®æ ‡çš„å½¢çŠ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 9, 21128])\n",
      "Targets shape: torch.Size([2, 9])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å¯¹äº PyTorch ä¸­çš„ `cross_entropy` å‡½æ•°ï¼Œæˆ‘ä»¬å¸Œæœ›é€šè¿‡åœ¨æ‰¹é‡ç»´åº¦ä¸Šç»„åˆè¿™äº›å¼ é‡æ¥å±•å¹³å®ƒä»¬ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([18, 21128])\n",
      "Flattened targets: torch.Size([18])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- è¯·æ³¨æ„ï¼Œç›®æ ‡æ˜¯æ ‡è®° IDï¼Œå®ƒä»¬ä¹Ÿä»£è¡¨æˆ‘ä»¬æƒ³è¦æœ€å¤§åŒ–çš„ logits å¼ é‡ä¸­çš„ç´¢å¼•ä½ç½®\n",
    "- PyTorch ä¸­çš„ `cross_entropy` å‡½æ•°å°†è‡ªåŠ¨è´Ÿè´£åœ¨è¦æœ€å¤§åŒ–çš„ logits ä¸­çš„æ ‡è®°ç´¢å¼•ä¸Šå†…éƒ¨åº”ç”¨ softmax å’Œå¯¹æ•°æ¦‚ç‡è®¡ç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.2085)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ä¸äº¤å‰ç†µæŸå¤±ç›¸å…³çš„ä¸€ä¸ªæ¦‚å¿µæ˜¯ LLM çš„å›°æƒ‘åº¦\n",
    "- å›°æƒ‘åº¦åªæ˜¯äº¤å‰ç†µæŸå¤±çš„æŒ‡æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(27132.2910)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å›°æƒ‘åº¦é€šå¸¸è¢«è®¤ä¸ºæ›´å…·å¯è§£é‡Šæ€§ï¼Œå› ä¸ºå®ƒå¯ä»¥ç†è§£ä¸ºæ¨¡å‹åœ¨æ¯ä¸ªæ­¥éª¤ä¸­ä¸ç¡®å®šçš„æœ‰æ•ˆè¯æ±‡é‡ï¼ˆåœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œå³ 27,132 ä¸ªå­—æˆ–æ ‡è®°ï¼‰\n",
    "- æ¢å¥è¯è¯´ï¼Œå›°æƒ‘åº¦è¡¡é‡äº†æ¨¡å‹é¢„æµ‹çš„æ¦‚ç‡åˆ†å¸ƒä¸æ•°æ®é›†ä¸­å•è¯çš„å®é™…åˆ†å¸ƒçš„åŒ¹é…ç¨‹åº¦\n",
    "- ä¸æŸå¤±ç±»ä¼¼ï¼Œå›°æƒ‘åº¦è¶Šä½ï¼Œè¡¨ç¤ºæ¨¡å‹é¢„æµ‹è¶Šæ¥è¿‘å®é™…åˆ†å¸ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 è®¡ç®—è®­ç»ƒé›†å’ŒéªŒè¯é›†æŸå¤±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æˆ‘ä»¬ä½¿ç”¨ç›¸å¯¹è¾ƒå°çš„æ•°æ®é›†æ¥è®­ç»ƒ LLMï¼ˆå®é™…ä¸Šï¼Œåªæœ‰ä¸€ä¸ªçŸ­ç¯‡æ•…äº‹ï¼‰\n",
    "- åŸå› æ˜¯ï¼š\n",
    "  - æ‚¨å¯ä»¥åœ¨æ²¡æœ‰åˆé€‚ GPU çš„ç¬”è®°æœ¬ç”µè„‘ä¸Šå‡ åˆ†é’Ÿå†…è¿è¡Œä»£ç ç¤ºä¾‹\n",
    "  - è®­ç»ƒå®Œæˆç›¸å¯¹è¾ƒå¿«ï¼ˆå‡ åˆ†é’Ÿè€Œä¸æ˜¯å‡ å‘¨ï¼‰ï¼Œè¿™å¯¹äºæ•™è‚²ç›®çš„å¾ˆæœ‰å¸®åŠ©\n",
    "  - æˆ‘ä»¬ä½¿ç”¨æ¥è‡ªå…¬å…±é¢†åŸŸçš„æ–‡æœ¬ï¼Œå¯ä»¥å°†å…¶åŒ…å«åœ¨æ­¤ GitHub å­˜å‚¨åº“ä¸­ï¼Œè€Œä¸ä¼šä¾µçŠ¯ä»»ä½•ä½¿ç”¨æƒæˆ–å¢åŠ å­˜å‚¨åº“å¤§å°\n",
    "\n",
    "- ä¾‹å¦‚ï¼ŒLlama 2 7B éœ€è¦åœ¨ A100 GPU ä¸ŠèŠ±è´¹ 184,320 ä¸ª GPU å°æ—¶æ‰èƒ½åœ¨ 2 ä¸‡äº¿ä¸ªä»¤ç‰Œä¸Šè¿›è¡Œè®­ç»ƒ\n",
    "  - åœ¨æ’°å†™æœ¬æ–‡æ—¶ï¼ŒAWS ä¸Š 8xA100 äº‘æœåŠ¡å™¨çš„æ¯å°æ—¶æˆæœ¬çº¦ä¸º \\$30\n",
    "  - å› æ­¤ï¼Œé€šè¿‡å¼€ç®±å³ç”¨çš„è®¡ç®—ï¼Œè®­ç»ƒè¿™ä¸ª LLM å°†èŠ±è´¹ 184,320 / 8 * \\$30 = \\$690,000\n",
    "\n",
    "- ä¸‹é¢ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸ç¬¬ 2 ç« ç›¸åŒçš„æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/GavinHome/LLMs-from-scratch-zh/main/ch02/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- é€šè¿‡æ‰“å°å‰ 100 ä¸ªå­—å’Œå 100 ä¸ªå­—æ¥å¿«é€Ÿæ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŠ è½½æ­£å¸¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘ä¸€ç›´è®¤ä¸ºæ°å…‹Â·å‰æ–¯ä¼¯æ©æ˜¯ä¸€ä¸ªå»‰ä»·çš„å¤©æ‰â€”â€”å°½ç®¡ä»–æ˜¯ä¸ªä¸é”™çš„å®¶ä¼™â€”â€”æ‰€ä»¥å½“æˆ‘å¬è¯´ä»–åœ¨äº‹ä¸šå·…å³°æ—¶æ”¾å¼ƒäº†ç»˜ç”»ï¼Œå¨¶äº†ä¸€ä½å¯Œæœ‰çš„å¯¡å¦‡ï¼Œå¹¶åœ¨é‡Œç»´åŸƒæ‹‰çš„ä¸€åº§åˆ«å¢…é‡Œå®‰é¡¿ä¸‹æ¥æ—¶ï¼Œæˆ‘å¹¶ä¸æ„Ÿåˆ°ç‰¹åˆ«æƒŠè®¶ã€‚ï¼ˆè™½ç„¶æˆ‘æ›´å€¾å‘äº\n"
     ]
    }
   ],
   "source": [
    "# First 100 characters\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€”â€”åªæ˜¯åœ¨å¾·æ–‡éƒ¡ä»ä¸€æ¬¡å¿ƒè„ç—…å‘ä½œæ¢å¤æœŸé—´ï¼Œç”¨é¢¤æŠ–çš„æ‰‹è®°å½•ä¸‹çš„ä¸€ä¸ªç¬”è®°ã€‚åªæ˜¯ä¸€ä¸ªç¬”è®°ï¼ä½†å®ƒè®²è¿°äº†ä»–çš„æ•´ä¸ªå†å²ã€‚æ¯ä¸€ç¬”éƒ½å……æ»¡äº†å¤šå¹´çš„è€å¿ƒè€Œè”‘è§†çš„åšæŒã€‚éšæ³¢é€æµçš„äººæ°¸è¿œå­¦ä¸ä¼šé‚£ç§å¼ºå¤§çš„é€†æµè€Œä¸Šçš„ç¬”è§¦â€¦â€¦â€\n"
     ]
    }
   ],
   "source": [
    "# Last 100 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 2806\n",
      "Tokens: 2758\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æ–‡æœ¬åªæœ‰ 2,758 ä¸ª tokenï¼Œå¯¹äºè®­ç»ƒ LLM æ¥è¯´å¤ªçŸ­äº†ï¼Œä½†åŒæ ·ï¼Œè¿™æ˜¯å‡ºäºå­¦ä¹ ç›®çš„ï¼ˆæˆ‘ä»¬ç¨åè¿˜å°†åŠ è½½é¢„è®­ç»ƒçš„æƒé‡ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ•°æ®é›†åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œå¹¶ä½¿ç”¨ç¬¬ 2 ç« ä¸­çš„æ•°æ®åŠ è½½å™¨ä¸º LLM è®­ç»ƒå‡†å¤‡æ‰¹æ¬¡\n",
    "- å‡ºäºå¯è§†åŒ–ç›®çš„ï¼Œä¸‹å›¾å‡è®¾ `max_length=6`ï¼Œä½†å¯¹äºè®­ç»ƒåŠ è½½å™¨ï¼Œæˆ‘ä»¬å°† `max_length` è®¾ç½®ä¸º LLM æ”¯æŒçš„ä¸Šä¸‹æ–‡é•¿åº¦\n",
    "- ä¸‹å›¾ä»…æ˜¾ç¤ºè¾“å…¥æ ‡è®°ä»¥æ–¹ä¾¿ç†è§£\n",
    "  - ç”±äºæˆ‘ä»¬è®­ç»ƒ LLM æ¥é¢„æµ‹æ–‡æœ¬ä¸­çš„ä¸‹ä¸€ä¸ªå•è¯ï¼Œå› æ­¤ç›®æ ‡çœ‹èµ·æ¥ä¸è¿™äº›è¾“å…¥ç›¸åŒï¼Œåªæ˜¯ç›®æ ‡ç§»åŠ¨äº†ä¸€ä¸ªä½ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.80\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æˆ‘ä»¬ä½¿ç”¨ç›¸å¯¹è¾ƒå°çš„æ‰¹å¤„ç†å¤§å°æ¥å‡å°‘è®¡ç®—èµ„æºéœ€æ±‚ï¼Œå› ä¸ºæ•°æ®é›†ä¸€â€‹â€‹å¼€å§‹å°±å¾ˆå°\n",
    "- ä¾‹å¦‚ï¼ŒLlama 2 7B çš„æ‰¹å¤„ç†å¤§å°ä¸º 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å¯é€‰æ£€æŸ¥æ•°æ®æ˜¯å¦å·²æ­£ç¡®åŠ è½½ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å¦ä¸€ä¸ªå¯é€‰æ£€æŸ¥æ˜¯æ£€æŸ¥ä»¤ç‰Œå¤§å°æ˜¯å¦åœ¨é¢„æœŸçš„èŒƒå›´å†…ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 2048\n",
      "Validation tokens: 512\n",
      "All tokens: 2560\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å®ç°ä¸€ä¸ªæ•ˆç”¨å‡½æ•°æ¥è®¡ç®—ç»™å®šæ‰¹æ¬¡çš„äº¤å‰ç†µæŸå¤±\n",
    "- æ­¤å¤–ï¼Œæˆ‘ä»¬å®ç°ç¬¬äºŒä¸ªæ•ˆç”¨å‡½æ•°æ¥è®¡ç®—æ•°æ®åŠ è½½å™¨ä¸­ç”¨æˆ·æŒ‡å®šæ‰¹æ¬¡æ•°é‡çš„æŸå¤±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å¦‚æœæ‚¨çš„æœºå™¨é…æœ‰æ”¯æŒ CUDA çš„ GPUï¼ŒLLM å°†åœ¨ GPU ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè€Œæ— éœ€å¯¹ä»£ç è¿›è¡Œä»»ä½•æ›´æ”¹\n",
    "- é€šè¿‡ `device` è®¾ç½®ï¼Œæˆ‘ä»¬ç¡®ä¿æ•°æ®åŠ è½½åˆ°ä¸ LLM æ¨¡å‹ç›¸åŒçš„è®¾å¤‡ä¸Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.11281442642212\n",
      "Validation loss: 10.10297679901123\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(42) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 è®­ç»ƒä¸€ä¸ªLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬æœ€ç»ˆå®ç°äº†è®­ç»ƒ LLM çš„ä»£ç \n",
    "- æˆ‘ä»¬ä¸“æ³¨äºä¸€ä¸ªç®€å•çš„è®­ç»ƒå‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„è®­ç»ƒå‡½æ•°æ¥è®­ç»ƒ LLMï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 8.727, Val loss 9.104\n",
      "æ¯ ä¸€ æ¬¡ åŠª åŠ› éƒ½ è®© ä½  æ„Ÿ åŠ¨ æˆ‘\n",
      "Ep 2 (Step 000005): Train loss 6.972, Val loss 6.983\n",
      "æ¯ ä¸€ æ¬¡ åŠª åŠ› éƒ½ è®© ä½  æ„Ÿ åŠ¨ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„ çš„\n",
      "Ep 3 (Step 000010): Train loss 5.668, Val loss 5.832\n",
      "æ¯ ä¸€ æ¬¡ åŠª åŠ› éƒ½ è®© ä½  æ„Ÿ åŠ¨ æˆ‘ ï¼Œ æˆ‘ ï¼Œ æˆ‘ ã€‚\n",
      "Ep 4 (Step 000015): Train loss 4.514, Val loss 5.163\n",
      "æ¯ ä¸€ æ¬¡ åŠª åŠ› éƒ½ è®© ä½  æ„Ÿ åŠ¨ ï¼Œ æˆ‘ ä¸ æ˜¯ æˆ‘ ä¸ æˆ‘ ä¸ åˆ° ï¼Œ æˆ‘ ä¸ åˆ° ï¼Œ æˆ‘ ä¸ åˆ° ï¼Œ æˆ‘ ä¸ åˆ° ï¼Œ æˆ‘ ä¸ åˆ° äº† æˆ‘ ä¸ åˆ° ï¼Œ æˆ‘ ä¸ æ˜¯ æˆ‘ ä¸ åˆ° ï¼Œ æˆ‘ ä¸ åˆ° ä»– æ˜¯ ä¸€ ä¸ª åˆ° ä»– æ˜¯ æˆ‘ ä¸ åˆ°\n",
      "æ¯ ä¸€ æ¬¡ åŠª åŠ› éƒ½ è®© ä½  æ„Ÿ åŠ¨ æ˜¯ ä¸€ ä¸ª æ¬¡ ï¼Œ æˆ‘ ä¸ æ˜¯ ä¸€ ä¸ª æˆ‘ çš„ ä½œ å“ ä»– çš„ ä¸€ ä¸ª\n",
      "Ep 6 (Step 000020): Train loss 3.413, Val loss 4.921\n",
      "æ¯ ä¸€ æ¬¡ åŠª åŠ› éƒ½ è®© ä½  æ„Ÿ åŠ¨ æˆ‘ çš„ ä¸€ æ¬¡ ï¼Œ ä»– çš„ æˆ‘ æˆ‘ çš„ æˆ‘ ä¸ åˆ° è¿™ æ · çš„ ä»– æ˜¯ æˆ‘ çš„ æˆ‘ çš„ æˆ‘ çš„ æˆ‘ çš„ æˆ‘ ï¼Œ è¿™ ä¸ª æˆ‘ çš„ æˆ‘ çš„\n",
      "Ep 7 (Step 000025): Train loss 2.500, Val loss 4.222\n",
      "æ¯ ä¸€ æ¬¡ åŠª åŠ› éƒ½ è®© ä½  æ„Ÿ åŠ¨ äº† ä¸€ æ¬¡ ï¼Œ å½“ ç„¶ çš„\n",
      "Ep 8 (Step 000030): Train loss 1.755, Val loss 3.816\n",
      "æ¯ ä¸€ æ¬¡ åŠª åŠ› éƒ½ è®© ä½  æ„Ÿ åŠ¨ äº† æˆ‘ ä¸€ ä¸ª å»‰ ä»· æˆ‘ å‘ ä½œ å“ å¹¶ ä¸ èƒ½ çœ‹ åˆ° ä»– çš„ éƒ¨ åˆ† ã€‚ æˆ‘ çš„ é‚£ äº› å ä¸½ çš„ éƒ¨ åˆ† ã€‚\n",
      "Ep 9 (Step 000035): Train loss 1.128, Val loss 3.648\n",
      "æ¯ ä¸€ æ¬¡ åŠª åŠ› éƒ½ è®© ä½  æ„Ÿ åŠ¨ äº† ä¸€ ä¸ª ä¸ èƒ½ å¹³ æˆ‘ çœ‹ åˆ° ï¼Œ å½“ æ–¯ ç‰¹ åŠ³ å¾· ç”» ä¸‹ ç¬¬ ä¸€ ä¸ª æ—¶ ï¼Œ ä»– ã€‚ æˆ‘ çš„ æ‰‹ çš„ ç»“ æœ ä¼š æ˜¯ ä»€ ä¹ˆ ã€‚ ä»– å·² ç» æŒ æ¡ äº† ä¸€ ä¸ª ä¸» é¢˜ ï¼Œ ä»– çš„ ç€\n",
      "æ¯ ä¸€ æ¬¡ åŠª åŠ› éƒ½ è®© ä½  æ„Ÿ åŠ¨ åœ¨ äº” åˆ† é’Ÿ å†… å‘Š è¯‰ ä½  ä»– æ˜¯ ä¸ª ä¸ éœ€ è¦ å¾ˆ é•¿ æ—¶ é—´ æˆ‘ çš„ æ»¡ è¶³ è€Œ æ„Ÿ åˆ° é«˜ å…´ ï¼š å¾ˆ é«˜ å…´ èƒ½ æœ‰ è¿™ æ · ä¸€ ä¸ª ä¸» é¢˜ ï¼Œ ä»– çš„ ç€\n",
      "Training completed in 1.45 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"æ¯ä¸€æ¬¡åŠªåŠ›éƒ½è®©ä½ æ„ŸåŠ¨\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æŸ¥çœ‹ä¸Šé¢çš„ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¨¡å‹ä¸€å¼€å§‹ä¼šç”Ÿæˆéš¾ä»¥ç†è§£çš„å­—ç¬¦ä¸²ï¼Œè€Œåˆ°æœ€åï¼Œå®ƒèƒ½å¤Ÿç”Ÿæˆè¯­æ³•æˆ–å¤šæˆ–å°‘æ­£ç¡®çš„å¥å­\n",
    "- ä½†æ˜¯ï¼ŒåŸºäºè®­ç»ƒå’ŒéªŒè¯é›†æŸå¤±ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¨¡å‹å¼€å§‹è¿‡åº¦æ‹Ÿåˆ\n",
    "- å¦‚æœæˆ‘ä»¬æ£€æŸ¥å®ƒåœ¨æœ€åå†™çš„å‡ æ®µè¯ï¼Œæˆ‘ä»¬ä¼šå‘ç°å®ƒä»¬é€å­—é€å¥åœ°åŒ…å«åœ¨è®­ç»ƒé›†ä¸­â€”â€”å®ƒåªæ˜¯è®°ä½äº†è®­ç»ƒæ•°æ®\n",
    "- ç¨åï¼Œæˆ‘ä»¬å°†ä»‹ç»å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šå‡è½»è¿™ç§è®°å¿†çš„è§£ç ç­–ç•¥\n",
    "- è¯·æ³¨æ„ï¼Œè¿™é‡Œå‘ç”Ÿè¿‡åº¦æ‹Ÿåˆæ˜¯å› ä¸ºæˆ‘ä»¬æœ‰ä¸€ä¸ªéå¸¸éå¸¸å°çš„è®­ç»ƒé›†ï¼Œå¹¶ä¸”æˆ‘ä»¬å¯¹å…¶è¿›è¡Œäº†å¤šæ¬¡è¿­ä»£\n",
    "  - è¿™é‡Œçš„ LLM åŸ¹è®­ä¸»è¦ç”¨äºæ•™è‚²ç›®çš„ï¼›æˆ‘ä»¬ä¸»è¦æƒ³çœ‹çœ‹æ¨¡å‹å¯ä»¥å­¦ä¼šç”Ÿæˆè¿è´¯çš„æ–‡æœ¬\n",
    "  - æˆ‘ä»¬ä¸æ˜¯èŠ±è´¹æ•°å‘¨æˆ–æ•°æœˆåœ¨å¤§é‡æ˜‚è´µçš„ç¡¬ä»¶ä¸Šè®­ç»ƒè¿™ä¸ªæ¨¡å‹ï¼Œè€Œæ˜¯ç¨ååŠ è½½é¢„è®­ç»ƒçš„æƒé‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 æ§åˆ¶éšæœºæ€§çš„è§£ç ç­–ç•¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ä½¿ç”¨ç›¸å¯¹è¾ƒå°çš„ LLM ä½œä¸ºæˆ‘ä»¬ä¸Šé¢è®­ç»ƒçš„ GPT æ¨¡å‹ï¼Œæ¨ç†ç›¸å¯¹ä¾¿å®œï¼Œå› æ­¤å¦‚æœæ‚¨åœ¨ä¸Šé¢ä½¿ç”¨ GPU è¿›è¡Œè®­ç»ƒï¼Œåˆ™æ— éœ€ä½¿ç”¨ GPU\n",
    "- ä½¿ç”¨æˆ‘ä»¬ä¹‹å‰åœ¨ç®€å•è®­ç»ƒå‡½æ•°ä¸­ä½¿ç”¨çš„ `generate_text_simple` å‡½æ•°ï¼ˆæ¥è‡ªä¸Šä¸€ç« ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥ä¸€æ¬¡ç”Ÿæˆä¸€ä¸ªæ–°æ–‡æœ¬\n",
    "- å¦‚ç¬¬ 5.1.2 èŠ‚æ‰€è¿°ï¼Œä¸‹ä¸€ä¸ªç”Ÿæˆçš„æ ‡è®°æ˜¯è¯æ±‡è¡¨ä¸­æ‰€æœ‰æ ‡è®°ä¸­æ¦‚ç‡å¾—åˆ†æœ€å¤§çš„æ ‡è®°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " æ¯ ä¸€ æ¬¡ åŠª åŠ› éƒ½ è®© ä½  æ„Ÿ åŠ¨ åœ¨ äº” åˆ† é’Ÿ å†… å‘Š è¯‰ ä½  ä»– æ˜¯ ä¸ª ä¸ éœ€ è¦ å¾ˆ é•¿ æ—¶ é—´ æˆ‘ çš„ æ»¡ è¶³ è€Œ æ„Ÿ åˆ° é«˜ å…´ ï¼š å¾ˆ é«˜ å…´ èƒ½ æœ‰ è¿™ æ · ä¸€ ä¸ª ä¸» é¢˜ ï¼Œ ä»– çš„ ç€\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "# tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"æ¯ä¸€æ¬¡åŠªåŠ›éƒ½è®©ä½ æ„ŸåŠ¨\", tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å³ä½¿æˆ‘ä»¬å¤šæ¬¡æ‰§è¡Œä¸Šé¢çš„ `generate_text_simple` å‡½æ•°ï¼ŒLLM ä¹Ÿå§‹ç»ˆä¼šç”Ÿæˆç›¸åŒçš„è¾“å‡º\n",
    "- æˆ‘ä»¬ç°åœ¨å¼•å…¥ä¸¤ä¸ªæ¦‚å¿µï¼Œå³æ‰€è°“çš„è§£ç ç­–ç•¥ï¼Œæ¥ä¿®æ”¹ `generate_text_simple`ï¼š*æ¸©åº¦ç¼©æ”¾* å’Œ *top-k* é‡‡æ ·\n",
    "- è¿™äº›å°†å…è®¸æ¨¡å‹æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§å’Œå¤šæ ·æ€§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 æ¸©åº¦ç¼©æ”¾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ä»¥å‰ï¼Œæˆ‘ä»¬æ€»æ˜¯ä½¿ç”¨ `torch.argmax` å°†æ¦‚ç‡æœ€é«˜çš„æ ‡è®°ä½œä¸ºä¸‹ä¸€ä¸ªæ ‡è®°è¿›è¡Œé‡‡æ ·\n",
    "- ä¸ºäº†å¢åŠ å¤šæ ·æ€§ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `torch.multinomial(probs, num_samples=1)` ä»æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·ä¸‹ä¸€ä¸ªæ ‡è®°\n",
    "- åœ¨è¿™é‡Œï¼Œæ¯ä¸ªç´¢å¼•è¢«é€‰ä¸­çš„æ¦‚ç‡å¯¹åº”äºå…¶åœ¨è¾“å…¥å¼ é‡ä¸­çš„æ¦‚ç‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æˆ‘ä»¬å¯ä»¥é€šè¿‡ç§°ä¸ºæ¸©åº¦ç¼©æ”¾çš„æ¦‚å¿µæ¥æ§åˆ¶åˆ†å¸ƒå’Œé€‰æ‹©è¿‡ç¨‹\n",
    "- â€œæ¸©åº¦ç¼©æ”¾â€åªæ˜¯ä¸€ä¸ªèŠ±å“¨çš„è¯ï¼Œç”¨äºå°† logits é™¤ä»¥å¤§äº 0 çš„æ•°å­—\n",
    "- åœ¨åº”ç”¨ softmax åï¼Œå¤§äº 1 çš„æ¸©åº¦å°†äº§ç”Ÿæ›´å‡åŒ€åˆ†å¸ƒçš„æ ‡è®°æ¦‚ç‡\n",
    "- åœ¨åº”ç”¨ softmax åï¼Œå°äº 1 çš„æ¸©åº¦å°†äº§ç”Ÿæ›´å¯ä¿¡ï¼ˆæ›´å°–é”æˆ–æ›´å°–é”ï¼‰çš„åˆ†å¸ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k æŠ½æ ·"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ä¸ºäº†èƒ½å¤Ÿä½¿ç”¨æ›´é«˜çš„æ¸©åº¦æ¥å¢åŠ è¾“å‡ºå¤šæ ·æ€§å¹¶é™ä½æ— æ„ä¹‰å¥å­çš„æ¦‚ç‡ï¼Œæˆ‘ä»¬å¯ä»¥å°†é‡‡æ ·çš„æ ‡è®°é™åˆ¶ä¸ºå‰ k ä¸ªæœ€å¯èƒ½çš„æ ‡è®°ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 ä¿®æ”¹æ–‡æœ¬ç”Ÿæˆå‡½æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å‰ä¸¤å°èŠ‚ä»‹ç»äº†æ¸©åº¦é‡‡æ ·å’Œ top-k é‡‡æ ·\n",
    "- è®©æˆ‘ä»¬ä½¿ç”¨è¿™ä¸¤ä¸ªæ¦‚å¿µä¿®æ”¹æˆ‘ä»¬ä¹‹å‰é€šè¿‡ LLM ç”Ÿæˆæ–‡æœ¬æ—¶ä½¿ç”¨çš„ `generate_simple` å‡½æ•°ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„ `generate` å‡½æ•°ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " æ¯ ä¸€ æ¬¡ åŠª åŠ› éƒ½ è®© ä½  ï¼Œ ä»– åœ¨ çœ‹ ä½† è¿™ ä¼š é‚£ ç”Ÿ äº† ä»– è€Œ ä¸” æœ‰ äºº ã€‚ ç”» ä¸‹ ç¬¬ ä¸€ ä»– å·² ç» æœ‰ äºŒ å ä¸Š çš„ ä½œ å“ ï¼› æœ ä¼š ï¼Œ è¿™ é‡Œ æ—¶ å€™ é€ è¦ ä¹ˆ æ—¶ ï¼Œ å¨¶ ä»– ï¼› ä»– åª æ˜¯\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"æ¯ä¸€æ¬¡åŠªåŠ›éƒ½è®©ä½ \", tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 åœ¨ PyTorch ä¸­åŠ è½½å’Œä¿å­˜æ¨¡å‹æƒé‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- è®­ç»ƒ LLM çš„è®¡ç®—æˆæœ¬å¾ˆé«˜ï¼Œå› æ­¤ä¿å­˜å’ŒåŠ è½½ LLM æƒé‡çš„èƒ½åŠ›è‡³å…³é‡è¦\n",
    "- PyTorch ä¸­æ¨èçš„æ–¹å¼æ˜¯é€šè¿‡å°† `torch.save` å‡½æ•°åº”ç”¨äº `.state_dict()` æ–¹æ³•æ¥ä¿å­˜æ¨¡å‹æƒé‡ï¼Œå³æ‰€è°“çš„ `state_dict`ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- é€šå¸¸ä½¿ç”¨ Adam æˆ– AdamW ç­‰è‡ªé€‚åº”ä¼˜åŒ–å™¨æ¥è®­ç»ƒ LLMï¼Œè€Œä¸æ˜¯ä½¿ç”¨å¸¸è§„çš„ SGD\n",
    "- è¿™äº›è‡ªé€‚åº”ä¼˜åŒ–å™¨ä¼šä¸ºæ¯ä¸ªæ¨¡å‹æƒé‡å­˜å‚¨é¢å¤–çš„å‚æ•°ï¼Œå› æ­¤å¦‚æœæˆ‘ä»¬è®¡åˆ’ç¨åç»§ç»­è¿›è¡Œé¢„è®­ç»ƒï¼Œé‚£ä¹ˆä¿å­˜è¿™äº›å‚æ•°ä¹Ÿæ˜¯æœ‰æ„ä¹‰çš„ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ç„¶åæˆ‘ä»¬å¯ä»¥å°†æ¨¡å‹æƒé‡åŠ è½½åˆ°æ–°çš„ `GPTModel` æ¨¡å‹å®ä¾‹ä¸­ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
